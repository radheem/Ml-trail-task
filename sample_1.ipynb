{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns \n",
    "from pylab import *\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "import warnings                        # To ignore any warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# classifiers\n",
    "from sklearn import linear_model \n",
    "\n",
    "import os\n",
    "import logging\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the data processing pipeline\n",
    "def preprocessing(data):\n",
    "    ''' data: the complete file \n",
    "     returns: a dataframe with selected features and no missing values '''\n",
    "    #computing y(preditor variable) \n",
    "    y = 0.5*(data[\"MinTemp\"]+data[\"MaxTemp\"])\n",
    "    data[\"AvgTemp\"] = y\n",
    "    #reducing dataset only to relavent variables (variables that have a high correlation and are concerned with Temperature)\n",
    "    df = data[[\"MinTemp\",\"MaxTemp\",\"Temp9am\",\"Temp3pm\",\"AvgTemp\"]]\n",
    "    # filling in missing values \n",
    "    df = df.interpolate()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a cross validation solution to the problem\n",
    "def cross_validation_fit(data):\n",
    "    data = preprocessing(data)\n",
    "    X = data[[\"MinTemp\",\"MaxTemp\",\"Temp9am\",\"Temp3pm\",\"AvgTemp\"]]\n",
    "    y= data[\"AvgTemp\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3)\n",
    "    models = {\n",
    "    \"LinearReg\": linear_model.LinearRegression(),\n",
    "    \"Ridge\" : linear_model.Ridge(alpha=1.0),\n",
    "    \"Lasso\": linear_model.Lasso(alpha=0.1)    \n",
    "    }\n",
    "    for model_name,model in models.items():\n",
    "        cv_results = cross_validate(model, X, y, cv=10,scoring=['r2','neg_mean_squared_error','neg_mean_absolute_error'])\n",
    "        print(\"model: \",model_name)\n",
    "        print(\"mean fit time: \",cv_results[\"fit_time\"].mean())\n",
    "        print(\"mean score time: \",cv_results[\"score_time\"].mean())\n",
    "        print(\"mean score r2: \",cv_results[\"test_r2\"].mean())\n",
    "        print(\"mean score mean_squared_error: \",-1*cv_results[\"test_neg_mean_squared_error\"].mean())\n",
    "        print(\"mean score mean_absolute_error: \",-1*cv_results[\"test_neg_mean_absolute_error\"].mean())\n",
    "        model_file_path = \"C:/Users/DELL/Documents/GitHub/Ml-trail-task/model_site/api/predictor/models/\"\n",
    "        model_file_path=model_file_path + \"/\" + model_name + \".sav\"\n",
    "        joblib.dump(model,model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a 70/30 split solution to the problem\n",
    "def manual_split_fit(data):\n",
    "    data = preprocessing(data)\n",
    "    X = data.iloc[:,0:-1]\n",
    "    y= data.iloc[:,-1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3)\n",
    "    # the list of models applied to the data \n",
    "    models = {\n",
    "    \"LinearReg\": linear_model.LinearRegression(),\n",
    "    \"Ridge\" : linear_model.Ridge(alpha=1.0),\n",
    "    \"Lasso\": linear_model.Lasso(alpha=0.1)    \n",
    "    }\n",
    "    for model_name,model in models.items():\n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(\"model: \",model_name)\n",
    "        print(\"the regession equation: {:.2f}x1 + {:.4f}x2 + {:.4f}x3 + {:.4f}x4 + {:.4f}\".format(model.coef_[0], model.coef_[1], model.coef_[2], model.coef_[3],model.intercept_) )\n",
    "        print(\"mean_squared_error: \",metrics.mean_squared_error(y_test,y_pred))\n",
    "        print(\"r2 error:\",metrics.r2_score(y_test,y_pred))\n",
    "        model_file_path = \"C:/Users/DELL/Documents/GitHub/Ml-trail-task/model_site/api/predictor/models/\"\n",
    "        model_file_path=model_file_path + \"/\" + model_name + \".sav\"\n",
    "        joblib.dump(model, model_file_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "dataset shape:  (142193, 22)\n"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/weatherAUS.csv\")\n",
    "data = data.set_index(keys=[\"Location\",\"Date\"])\n",
    "print(\"dataset shape: \",data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing Eploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count of missing values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MinTemp            637\nMaxTemp            322\nRainfall          1406\nEvaporation      60843\nSunshine         67816\nWindGustDir       9330\nWindGustSpeed     9270\nWindDir9am       10013\nWindDir3pm        3778\nWindSpeed9am      1348\nWindSpeed3pm      2630\nHumidity9am       1774\nHumidity3pm       3610\nPressure9am      14014\nPressure3pm      13981\nCloud9am         53657\nCloud3pm         57094\nTemp9am            904\nTemp3pm           2726\nRainToday         1406\nRISK_MM              0\nRainTomorrow         0\ndtype: int64\n"
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing predictor variable and checking correlation will other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing y(preditor variable) \n",
    "y = 0.5*(data[\"MinTemp\"]+data[\"MaxTemp\"])\n",
    "data[\"AvgTemp\"] = y\n",
    "cor = data.corr()['AvgTemp'][:]\n",
    "# plt.figure(figsize=(10,8))\n",
    "# plt.barh(cor.index,cor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bar plot above shows the correlation of AvgTemp with rest of the features<br>\n",
    "we pick features with correlation more than 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature selection and preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MinTemp    0\nMaxTemp    0\nTemp9am    0\nTemp3pm    0\nAvgTemp    0\ndtype: int64\n"
    }
   ],
   "source": [
    "data1 = preprocessing(data) # pick a highly correlated subset of features from the dataset and fill in null values \n",
    "print(data1.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Illustrating distribution of data before and after filling in missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"comparision of data distributions before an after filling missing values\")\n",
    "# sns.set(rc={\"figure.figsize\": (16, 16)}); \n",
    "# plt.title(\"Before vs After\")\n",
    "# subplot(4,2,1)\n",
    "# sns.distplot(data['MaxTemp'])\n",
    "# subplot(4,2,3)\n",
    "# sns.distplot(data['MinTemp'])\n",
    "# subplot(4,2,2)\n",
    "# sns.distplot(data1['MaxTemp'])\n",
    "# subplot(4,2,4)\n",
    "# sns.distplot(data1['MinTemp'])\n",
    "# subplot(4,2,5)\n",
    "# sns.distplot(data['Temp9am'])\n",
    "# subplot(4,2,7)\n",
    "# sns.distplot(data['Temp3pm'])\n",
    "# subplot(4,2,6)\n",
    "# sns.distplot(data1['Temp9am'])\n",
    "# subplot(4,2,8)\n",
    "# sns.distplot(data1['Temp3pm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As illustrated in the figure above the distribution of data doesn't change after filling in null values.<br>\n",
    "The rows with null enteries could have been removed but the ratio of null values is very small hence I decided to keep all rows and use interpolate because it linearly fills in values while maintaining the distribution of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "correlation among selected features\n          MinTemp   MaxTemp   Temp9am   Temp3pm   AvgTemp\nMinTemp  1.000000  0.736839  0.902156  0.709671  0.924223\nMaxTemp  0.736839  1.000000  0.887788  0.979792  0.938856\nTemp9am  0.902156  0.887788  1.000000  0.859329  0.959720\nTemp3pm  0.709671  0.979792  0.859329  1.000000  0.913784\nAvgTemp  0.924223  0.938856  0.959720  0.913784  1.000000\n"
    }
   ],
   "source": [
    "corr = data1.corr()\n",
    "print(\"correlation among selected features\")\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The main solution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "model:  LinearReg\nthe regession equation: 0.50x1 + 0.4953x2 + 0.0013x3 + 0.0036x4 + 0.0098\nmean_squared_error:  0.01669797474195746\nr2 error: 0.9995777909915415\nmodel:  Ridge\nthe regession equation: 0.50x1 + 0.4953x2 + 0.0013x3 + 0.0036x4 + 0.0098\nmean_squared_error:  0.01669797770130368\nr2 error: 0.9995777909167143\nmodel:  Lasso\nthe regession equation: 0.50x1 + 0.4966x2 + 0.0017x3 + 0.0014x4 + 0.0491\nmean_squared_error:  0.016936873709249387\nr2 error: 0.9995717504208937\n"
    }
   ],
   "source": [
    "manual_split_fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'sklearn.linear_model._coordinate_descent.Lasso'>\n"
    }
   ],
   "source": [
    "\n",
    "model_file_path = \"C:/Users/DELL/Documents/GitHub/Ml-trail-task/model_site/api/predictor/models/Lasso.sav\"\n",
    "data = pd.read_csv(\"data/weatherAUS.csv\")\n",
    "data = data.set_index(keys=[\"Location\",\"Date\"])\n",
    "data = preprocessing(data)\n",
    "X = data.iloc[:,0:-1]\n",
    "y= data.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3)\n",
    "\n",
    "model = joblib.load(model_file_path)\n",
    "print(type(model))\n",
    "result_val = model.score(X_train, y_train)\n",
    "result_test = model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.9996697506794318 0.9995977644078999\n"
    }
   ],
   "source": [
    "print(result_val,result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python37564bit88380ad151a64614b3411a8a1d6791f3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}